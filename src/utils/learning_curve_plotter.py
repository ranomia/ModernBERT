"""
å­¦ç¿’æ›²ç·šã‚’æç”»ã™ã‚‹ãŸã‚ã®ãƒ—ãƒ­ãƒƒã‚¿ãƒ¼ã‚¯ãƒ©ã‚¹
"""

import matplotlib.pyplot as plt
import numpy as np
from typing import Dict, List, Any, Optional
import os
from datetime import datetime

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆå¯¾å¿œ
try:
    import japanize_matplotlib
    print("âœ… japanize_matplotlib ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚æ—¥æœ¬èªè¡¨ç¤ºãŒæœ‰åŠ¹ã§ã™ã€‚")
except ImportError:
    print("âš ï¸  japanize_matplotlib ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚æ—¥æœ¬èªãŒæ–‡å­—åŒ–ã‘ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
    print("   pip install japanize-matplotlib ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚")


class LearningCurvePlotter:
    """å­¦ç¿’æ›²ç·šãƒ—ãƒ­ãƒƒã‚¿ãƒ¼ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        # å­¦ç¿’å±¥æ­´ã‚’ä¿å­˜ã™ã‚‹è¾æ›¸
        self.training_history = {}
        
        # ãƒ—ãƒ­ãƒƒãƒˆã®ã‚¹ã‚¿ã‚¤ãƒ«è¨­å®š
        self.colors = {
            'bert_train': '#1f77b4',       # é’ï¼ˆæ¿ƒï¼‰
            'bert_val': '#1f77b4',         # é’ï¼ˆåŒè‰²ã€ç·šç¨®ã§åŒºåˆ¥ï¼‰
            'modernbert_train': '#ff7f0e', # ã‚ªãƒ¬ãƒ³ã‚¸ï¼ˆæ¿ƒï¼‰
            'modernbert_val': '#ff7f0e',   # ã‚ªãƒ¬ãƒ³ã‚¸ï¼ˆåŒè‰²ã€ç·šç¨®ã§åŒºåˆ¥ï¼‰
        }
        
        self.line_styles = {
            'train': '-',   # å®Ÿç·š
            'val': '--',    # ç ´ç·š
        }
        
        self.markers = {
            'bert': 'o',        # ä¸¸
            'modernbert': 's',  # å››è§’
        }
    
    def initialize_model_history(self, model_name: str) -> None:
        """ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’å±¥æ­´ã‚’åˆæœŸåŒ–"""
        if model_name not in self.training_history:
            self.training_history[model_name] = {
                'epochs': [],
                'train_loss': [],
                'train_accuracy': [],
                'val_loss': [],
                'val_accuracy': []
            }
    
    def add_epoch_data(self, model_name: str, epoch: int, 
                      train_loss: float, train_accuracy: float,
                      val_loss: float, val_accuracy: float) -> None:
        """ã‚¨ãƒãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ """
        self.initialize_model_history(model_name)
        
        history = self.training_history[model_name]
        history['epochs'].append(epoch)
        history['train_loss'].append(train_loss)
        history['train_accuracy'].append(train_accuracy)
        history['val_loss'].append(val_loss)
        history['val_accuracy'].append(val_accuracy)
    
    def plot_learning_curves(self, save_dir: str = "results", 
                           show_plot: bool = True) -> None:
        """å­¦ç¿’æ›²ç·šã‚’ãƒ—ãƒ­ãƒƒãƒˆ"""
        if not self.training_history:
            print("âš ï¸  ãƒ—ãƒ­ãƒƒãƒˆã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            return
        
        # ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        os.makedirs(save_dir, exist_ok=True)
        
        # 2ã¤ã®ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆï¼ˆæ­£è§£ç‡ã¨lossï¼‰ã‚’ä½œæˆ
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
        
        # æ­£è§£ç‡ã®ãƒ—ãƒ­ãƒƒãƒˆ
        self._plot_accuracy(ax1)
        
        # lossã®ãƒ—ãƒ­ãƒƒãƒˆ
        self._plot_loss(ax2)
        
        # å…¨ä½“ã®ã‚¿ã‚¤ãƒˆãƒ«
        fig.suptitle('å­¦ç¿’æ›²ç·šæ¯”è¼ƒï¼ˆBERT vs ModernBERTï¼‰', fontsize=16, fontweight='bold')
        
        # æ¯”è¼ƒãƒ¢ãƒ‡ãƒ«æ•°ã‚’ç¢ºèª
        model_count = len(self.training_history)
        if model_count > 1:
            print(f"ğŸ“Š {model_count}ã¤ã®ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’æ›²ç·šã‚’åŒä¸€ãƒ—ãƒ­ãƒƒãƒˆä¸Šã«è¡¨ç¤ºã—ã¾ã™")
        
        # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆèª¿æ•´
        plt.tight_layout()
        
        # ä¿å­˜
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        save_path = os.path.join(save_dir, f"learning_curves_{timestamp}.png")
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"ğŸ“Š å­¦ç¿’æ›²ç·šã‚’ä¿å­˜ã—ã¾ã—ãŸ: {save_path}")
        
        # è¡¨ç¤º
        if show_plot:
            plt.show()
        else:
            plt.close()
    
    def _plot_accuracy(self, ax) -> None:
        """æ­£è§£ç‡ã‚’ãƒ—ãƒ­ãƒƒãƒˆ"""
        ax.set_title('ã‚¨ãƒãƒƒã‚¯ã”ã¨ã®æ­£è§£ç‡', fontsize=14, fontweight='bold')
        ax.set_xlabel('ã‚¨ãƒãƒƒã‚¯æ•°')
        ax.set_ylabel('æ­£è§£ç‡ (%)')
        ax.grid(True, alpha=0.3)
        
        for model_name, history in self.training_history.items():
            if not history['epochs']:
                continue
                
            # ãƒ¢ãƒ‡ãƒ«åã®æ­£è¦åŒ–
            model_type = self._get_model_type(model_name)
            
            # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ï¼ˆå®Ÿç·šï¼‰
            train_color = self.colors.get(f'{model_type}_train', '#1f77b4')
            ax.plot(history['epochs'], history['train_accuracy'], 
                   color=train_color, linestyle=self.line_styles['train'],
                   marker=self.markers.get(model_type, 'o'), markersize=6,
                   label=f'{model_name} (å­¦ç¿’)', linewidth=2)
            
            # æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ï¼ˆç ´ç·šï¼‰
            val_color = self.colors.get(f'{model_type}_val', '#aec7e8')
            ax.plot(history['epochs'], history['val_accuracy'], 
                   color=val_color, linestyle=self.line_styles['val'],
                   marker=self.markers.get(model_type, 'o'), markersize=6,
                   label=f'{model_name} (æ¨è«–)', linewidth=2)
        
        ax.legend(loc='best')
        ax.set_ylim([0, 100])
    
    def _plot_loss(self, ax) -> None:
        """lossã‚’ãƒ—ãƒ­ãƒƒãƒˆ"""
        ax.set_title('ã‚¨ãƒãƒƒã‚¯ã”ã¨ã®æå¤±å€¤', fontsize=14, fontweight='bold')
        ax.set_xlabel('ã‚¨ãƒãƒƒã‚¯æ•°')
        ax.set_ylabel('æå¤±å€¤ (Loss)')
        ax.grid(True, alpha=0.3)
        
        for model_name, history in self.training_history.items():
            if not history['epochs']:
                continue
                
            # ãƒ¢ãƒ‡ãƒ«åã®æ­£è¦åŒ–
            model_type = self._get_model_type(model_name)
            
            # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ï¼ˆå®Ÿç·šï¼‰
            train_color = self.colors.get(f'{model_type}_train', '#1f77b4')
            ax.plot(history['epochs'], history['train_loss'], 
                   color=train_color, linestyle=self.line_styles['train'],
                   marker=self.markers.get(model_type, 'o'), markersize=6,
                   label=f'{model_name} (å­¦ç¿’)', linewidth=2)
            
            # æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ï¼ˆç ´ç·šï¼‰
            val_color = self.colors.get(f'{model_type}_val', '#aec7e8')
            ax.plot(history['epochs'], history['val_loss'], 
                   color=val_color, linestyle=self.line_styles['val'],
                   marker=self.markers.get(model_type, 'o'), markersize=6,
                   label=f'{model_name} (æ¨è«–)', linewidth=2)
        
        ax.legend(loc='best')
        ax.set_yscale('log')  # ãƒ­ã‚°ã‚¹ã‚±ãƒ¼ãƒ«ã§lossã‚’è¡¨ç¤º
    
    def _get_model_type(self, model_name: str) -> str:
        """ãƒ¢ãƒ‡ãƒ«åã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ã‚’å–å¾—"""
        model_name_lower = model_name.lower()
        if 'modernbert' in model_name_lower:
            return 'modernbert'
        elif 'bert' in model_name_lower:
            return 'bert'
        else:
            return 'other'
    
    def save_training_history(self, save_dir: str = "results") -> None:
        """å­¦ç¿’å±¥æ­´ã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        import json
        
        os.makedirs(save_dir, exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        save_path = os.path.join(save_dir, f"training_history_{timestamp}.json")
        
        with open(save_path, 'w', encoding='utf-8') as f:
            json.dump(self.training_history, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“ å­¦ç¿’å±¥æ­´ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {save_path}")
    
    def print_summary(self) -> None:
        """å­¦ç¿’çµæœã®ã‚µãƒãƒªãƒ¼ã‚’å‡ºåŠ›"""
        if not self.training_history:
            print("âš ï¸  è¡¨ç¤ºã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            return
        
        print("\n" + "="*60)
        print("ğŸ“Š å­¦ç¿’çµæœã‚µãƒãƒªãƒ¼")
        print("="*60)
        
        for model_name, history in self.training_history.items():
            if not history['epochs']:
                continue
                
            print(f"\nğŸ¤– {model_name}")
            print(f"   ã‚¨ãƒãƒƒã‚¯æ•°: {len(history['epochs'])}")
            
            if history['train_accuracy']:
                best_train_acc = max(history['train_accuracy'])
                best_train_epoch = history['epochs'][history['train_accuracy'].index(best_train_acc)]
                print(f"   æœ€é«˜å­¦ç¿’æ­£è§£ç‡: {best_train_acc:.2f}% (ã‚¨ãƒãƒƒã‚¯ {best_train_epoch})")
            
            if history['val_accuracy']:
                best_val_acc = max(history['val_accuracy'])
                best_val_epoch = history['epochs'][history['val_accuracy'].index(best_val_acc)]
                print(f"   æœ€é«˜æ¨è«–æ­£è§£ç‡: {best_val_acc:.2f}% (ã‚¨ãƒãƒƒã‚¯ {best_val_epoch})")
            
            if history['train_loss']:
                final_train_loss = history['train_loss'][-1]
                print(f"   æœ€çµ‚å­¦ç¿’æå¤±: {final_train_loss:.4f}")
            
            if history['val_loss']:
                final_val_loss = history['val_loss'][-1]
                print(f"   æœ€çµ‚æ¨è«–æå¤±: {final_val_loss:.4f}")
        
        print("="*60)
    
    def compare_models(self) -> None:
        """ãƒ¢ãƒ‡ãƒ«é–“ã®æ¯”è¼ƒçµæœã‚’è¡¨ç¤º"""
        if len(self.training_history) < 2:
            print("âš ï¸  æ¯”è¼ƒã™ã‚‹ã«ã¯å°‘ãªãã¨ã‚‚2ã¤ã®ãƒ¢ãƒ‡ãƒ«ãŒå¿…è¦ã§ã™ã€‚")
            return
        
        print("\n" + "="*60)
        print("ğŸ† ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒçµæœ")
        print("="*60)
        
        # æœ€é«˜æ¨è«–æ­£è§£ç‡ã§æ¯”è¼ƒ
        best_models = {}
        for model_name, history in self.training_history.items():
            if history['val_accuracy']:
                best_acc = max(history['val_accuracy'])
                best_models[model_name] = best_acc
        
        if best_models:
            sorted_models = sorted(best_models.items(), key=lambda x: x[1], reverse=True)
            print("\nğŸ“ˆ æ¨è«–æ­£è§£ç‡ãƒ©ãƒ³ã‚­ãƒ³ã‚°:")
            for i, (model_name, acc) in enumerate(sorted_models, 1):
                emoji = "ğŸ¥‡" if i == 1 else "ğŸ¥ˆ" if i == 2 else "ğŸ¥‰"
                print(f"   {emoji} {model_name}: {acc:.2f}%")
        
        print("="*60)


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆç”¨ã‚³ãƒ¼ãƒ‰
    plotter = LearningCurvePlotter()
    
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
    for epoch in range(1, 6):
        # BERTã®ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
        plotter.add_epoch_data(
            "BERT", epoch,
            train_loss=1.5 - epoch*0.1,
            train_accuracy=20 + epoch*10,
            val_loss=1.6 - epoch*0.08,
            val_accuracy=18 + epoch*8
        )
        
        # ModernBERTã®ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
        plotter.add_epoch_data(
            "ModernBERT", epoch,
            train_loss=1.4 - epoch*0.12,
            train_accuracy=25 + epoch*12,
            val_loss=1.5 - epoch*0.1,
            val_accuracy=22 + epoch*10
        )
    
    # ãƒ—ãƒ­ãƒƒãƒˆä½œæˆ
    plotter.plot_learning_curves(show_plot=False)
    plotter.print_summary()
    plotter.compare_models() 
"""
ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ©Ÿèƒ½ä»˜ãModernBERT vs BERT æ€§èƒ½æ¯”è¼ƒãƒ¡ã‚¤ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import argparse
import sys
import os
import torch
from datetime import datetime

# ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from evaluation.evaluator import ModelEvaluator
from models.bert_model import BERTModel
from models.modern_bert_model import ModernBERTModel
from training.trainer import SimpleTrainer


def parse_arguments():
    """ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã‚’è§£æ"""
    parser = argparse.ArgumentParser(
        description="ModernBERT vs BERT æ€§èƒ½æ¯”è¼ƒè©•ä¾¡ï¼ˆãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ä»˜ãï¼‰",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )

    parser.add_argument(
        "--model",
        type=str,
        choices=["bert", "modern_bert", "both"],
        default="both",
        help="è©•ä¾¡ã™ã‚‹ãƒ¢ãƒ‡ãƒ«",
    )

    parser.add_argument("--batch_size", type=int, default=4, help="ãƒãƒƒãƒã‚µã‚¤ã‚º")
    parser.add_argument("--max_length", type=int, default=128, help="æœ€å¤§ç³»åˆ—é•·")
    parser.add_argument("--device", type=str, default="cpu", help="ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹")

    # ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°è¨­å®š
    parser.add_argument(
        "--finetune", action="store_true", help="ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿè¡Œ"
    )
    parser.add_argument(
        "--epochs", type=int, default=3, help="ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¨ãƒãƒƒã‚¯æ•°"
    )
    parser.add_argument("--learning_rate", type=float, default=2e-5, help="å­¦ç¿’ç‡")

    return parser.parse_args()


def finetune_and_evaluate(model_config, args, device):
    """ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¨è©•ä¾¡ã‚’å®Ÿè¡Œ"""
    model_name = model_config["name"]
    model_class = model_config["class"]
    model_args = model_config["args"]

    print(f"\n--- {model_name} ã®å‡¦ç†é–‹å§‹ ---")

    # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
    model = model_class(**model_args)

    if args.finetune:
        print(f"ğŸ“ {model_name} ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿè¡Œä¸­...")

        # ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè¡Œ
        trainer = SimpleTrainer(model, device, learning_rate=args.learning_rate)
        model = trainer.quick_finetune(
            tokenizer_name=model_args.get(
                "model_name", "cl-tohoku/bert-base-japanese-v3"
            ),
            num_epochs=args.epochs,
            batch_size=args.batch_size,
            max_length=args.max_length,
        )
    else:
        print(
            f"âš ï¸  {model_name} ã¯ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãªã—ã§è©•ä¾¡ã—ã¾ã™ï¼ˆæ€§èƒ½ãŒä½ã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼‰"
        )

    # è©•ä¾¡å®Ÿè¡Œ
    evaluator = ModelEvaluator(device=args.device)

    # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ä½œæˆ
    from data.data_loader import JCommonsenseQALoader

    data_loader_instance = JCommonsenseQALoader(
        tokenizer_name=model_args.get("model_name", "cl-tohoku/bert-base-japanese-v3")
    )
    data_loader = data_loader_instance.create_dataloader(
        split="validation",
        batch_size=args.batch_size,
        max_length=args.max_length,
        shuffle=False,
    )

    result = evaluator.evaluate_model(model, data_loader, model_name)

    # ãƒ¡ãƒ¢ãƒªè§£æ”¾
    del model
    torch.cuda.empty_cache() if torch.cuda.is_available() else None

    return result


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    print("ğŸ“š ModernBERT vs BERT æ€§èƒ½æ¯”è¼ƒè©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ï¼ˆãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å¯¾å¿œï¼‰")
    print("=" * 80)

    args = parse_arguments()
    device = torch.device(args.device)

    print(f"ğŸ”§ è¨­å®š:")
    print(f"  - ãƒ‡ãƒã‚¤ã‚¹: {device}")
    print(f"  - ãƒãƒƒãƒã‚µã‚¤ã‚º: {args.batch_size}")
    print(f"  - æœ€å¤§ç³»åˆ—é•·: {args.max_length}")
    print(f"  - ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°: {'âœ… æœ‰åŠ¹' if args.finetune else 'âŒ ç„¡åŠ¹'}")
    if args.finetune:
        print(f"  - ã‚¨ãƒãƒƒã‚¯æ•°: {args.epochs}")
        print(f"  - å­¦ç¿’ç‡: {args.learning_rate}")

    # ãƒ¢ãƒ‡ãƒ«è¨­å®š
    models_config = []

    if args.model in ["bert", "both"]:
        models_config.append(
            {
                "name": "BERT (æ±åŒ—å¤§v3)",
                "class": BERTModel,
                "args": {
                    "model_name": "cl-tohoku/bert-base-japanese-v3",
                    "num_choices": 5,
                },
            }
        )

    if args.model in ["modern_bert", "both"]:
        models_config.append(
            {
                "name": "ModernBERT (SB-Intuitions)",
                "class": ModernBERTModel,
                "args": {
                    "model_name": "sbintuitions/modernbert-ja-130m",
                    "num_choices": 5,
                },
            }
        )

    results = {}

    # å„ãƒ¢ãƒ‡ãƒ«ã‚’é †æ¬¡å‡¦ç†
    for model_config in models_config:
        try:
            result = finetune_and_evaluate(model_config, args, device)
            results[model_config["name"]] = result
        except Exception as e:
            print(f"âŒ {model_config['name']} ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            continue

    # çµæœã‚µãƒãƒªãƒ¼
    print("\n" + "=" * 80)
    print("ğŸ“Š **æœ€çµ‚çµæœã‚µãƒãƒªãƒ¼**")
    print("=" * 80)

    if not results:
        print("âŒ è©•ä¾¡çµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    print(f"ğŸ“‹ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: JCommonsenseQA (1,119ã‚µãƒ³ãƒ—ãƒ«)")
    print(f"ğŸ¯ ç†è«–çš„ãƒ©ãƒ³ãƒ€ãƒ æ€§èƒ½: 20.0% (5æŠå•é¡Œ)")
    print(f"âš™ï¸  ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°: {'å®Ÿè¡Œæ¸ˆã¿' if args.finetune else 'æœªå®Ÿè¡Œ'}")

    for model_name, result in results.items():
        accuracy = result["accuracy_metrics"]["accuracy"]
        f1_score = result["accuracy_metrics"]["f1_macro"]

        # æ€§èƒ½åˆ¤å®š
        if accuracy > 0.6:
            performance_icon = "ğŸ†"
            performance_text = "å„ªç§€"
        elif accuracy > 0.4:
            performance_icon = "ğŸ¥ˆ"
            performance_text = "è‰¯å¥½"
        elif accuracy > 0.25:
            performance_icon = "ğŸ¥‰"
            performance_text = "æ™®é€š"
        else:
            performance_icon = "âš ï¸"
            performance_text = "è¦æ”¹å–„"

        print(f"\n{performance_icon} **{model_name}** ({performance_text})")
        print(f"   âœ… æ­£è§£ç‡: {accuracy:.1%}")
        print(f"   ğŸ“Š F1ã‚¹ã‚³ã‚¢: {f1_score:.1%}")
        print(f"   ğŸ§® ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {result['model_info']['total_parameters']:,}")

    if not args.finetune:
        print("\nğŸ’¡ **æ”¹å–„ææ¡ˆ**:")
        print(
            "   æ€§èƒ½å‘ä¸Šã®ãŸã‚ã«ã€--finetuneã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’è©¦ã—ã¦ãã ã•ã„:"
        )
        print("   python main_with_training.py --finetune --epochs 5 --batch_size 4")


if __name__ == "__main__":
    main()
